{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt-Management in LangChain\n",
    "\n",
    "In diesem Notebook lernen wir die wichtigsten Aspekte des Prompt-Managements kennen:\n",
    "- Organisation und Versionierung von Prompts\n",
    "- LangChain Hub für Prompt-Sharing\n",
    "- Integration mit Langfuse für Monitoring und Tracking\n",
    "- Best Practices für Prompt-Management in größeren Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung: Benötigte Bibliotheken installieren\n",
    "\n",
    "Falls noch nicht installiert, müssen wir die benötigten Bibliotheken installieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Installation der benötigten Pakete (bei Bedarf ausführen)\n",
    "# !pip install langchain langchain-openai langfuse langchain-langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Importieren der benötigten Bibliotheken\n",
    "import os\n",
    "from datetime import datetime\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "import json\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "# Optional: Für Langfuse-Integration\n",
    "# from langfuse import Langfuse\n",
    "# from langfuse.client import StatelessTracer\n",
    "# from langchain_langfuse import LangfuseCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grundlagen: Organisiertes Prompt-Management\n",
    "\n",
    "Effektives Prompt-Management umfasst folgende Aspekte:\n",
    "- Strukturierte Speicherung von Prompts\n",
    "- Versionierung für Nachvollziehbarkeit\n",
    "- Wiederverwendbarkeit durch modulare Gestaltung\n",
    "- Testing und Evaluation\n",
    "\n",
    "Wir beginnen mit einfachen Methoden zur strukturierten Verwaltung von Prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Lokale Prompt-Verwaltung mit einfacher Versionierung\n",
    "class PromptManager:\n",
    "    def __init__(self, base_path=\"./prompts\"):\n",
    "        self.base_path = base_path\n",
    "        # Erstelle den Verzeichnispfad, falls er nicht existiert\n",
    "        os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    def save_prompt(self, prompt, name, version=None, metadata=None):\n",
    "        # Generiere einen Zeitstempel als Version, falls keine angegeben wurde\n",
    "        if version is None:\n",
    "            version = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Erstelle das Verzeichnis für diesen Prompt, falls es nicht existiert\n",
    "        prompt_dir = os.path.join(self.base_path, name)\n",
    "        os.makedirs(prompt_dir, exist_ok=True)\n",
    "        \n",
    "        # Speichere den Prompt und Metadaten\n",
    "        prompt_data = {\n",
    "            \"content\": prompt.to_json() if hasattr(prompt, \"to_json\") else str(prompt),\n",
    "            \"version\": version,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"metadata\": metadata or {}\n",
    "        }\n",
    "        \n",
    "        # Speichere als JSON-Datei\n",
    "        file_path = os.path.join(prompt_dir, f\"{version}.json\")\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(prompt_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        return file_path\n",
    "    \n",
    "    def list_versions(self, name):\n",
    "        prompt_dir = os.path.join(self.base_path, name)\n",
    "        if not os.path.exists(prompt_dir):\n",
    "            return []\n",
    "        \n",
    "        # Liste alle JSON-Dateien im Verzeichnis\n",
    "        versions = [f.replace(\".json\", \"\") for f in os.listdir(prompt_dir) if f.endswith(\".json\")]\n",
    "        return sorted(versions)\n",
    "    \n",
    "    def get_latest_version(self, name):\n",
    "        versions = self.list_versions(name)\n",
    "        if not versions:\n",
    "            return None\n",
    "        return versions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Beispiel: Erstellen und Speichern eines Prompts\n",
    "prompt_manager = PromptManager()\n",
    "\n",
    "# Einen einfachen Prompt erstellen\n",
    "kundenservice_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein hilfreicher Kundendienstmitarbeiter für {unternehmen}. \"\n",
    "             \"Du sollst immer freundlich, professionell und lösungsorientiert antworten.\"),\n",
    "    (\"human\", \"{kundenfrage}\")\n",
    "])\n",
    "\n",
    "# Prompt speichern mit Metadaten\n",
    "prompt_path = prompt_manager.save_prompt(\n",
    "    prompt=kundenservice_prompt, \n",
    "    name=\"kundenservice_basic\",\n",
    "    metadata={\n",
    "        \"autor\": \"Workshop-Team\",\n",
    "        \"verwendung\": \"Kundenservice-Chatbot\",\n",
    "        \"empfohlenes_modell\": \"gpt-3.5-turbo\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Prompt gespeichert unter: {prompt_path}\")\n",
    "print(f\"Verfügbare Versionen: {prompt_manager.list_versions('kundenservice_basic')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LangChain Hub für Prompt-Sharing\n",
    "\n",
    "Der LangChain Hub ist eine zentrale Plattform zur Verwaltung und gemeinsamen Nutzung von Prompts. Er bietet folgende Vorteile:\n",
    "- Zentrales Repository für Prompts\n",
    "- Versionskontrolle\n",
    "- Einfache Integration in LangChain-Anwendungen\n",
    "- Zusammenarbeit im Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Beispiel: Prompt aus dem LangChain Hub laden\n",
    "sentiment_prompt = hub.pull(\"borislove/customer-sentiment-analysis\")\n",
    "\n",
    "print(\"Geladener Prompt aus dem Hub:\")\n",
    "print(sentiment_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Beispiel für die Verwendung des geladenen Prompts\n",
    "client_letter = \"\"\"Ich bin von dem Produkt zutiefst enttäuscht. Nach nur zwei Wochen Nutzung ist die Verarbeitung bereits mangelhaft. Mehrere Knöpfe sind abgefallen und die Naht hat sich gelöst. Ich erwarte eine vollständige Rückerstattung und werde das Produkt definitiv nicht weiterempfehlen.\"\"\"\n",
    "\n",
    "format_instructions = \"\"\"Zusätzlich zur numerischen Klassifizierung sollst du eine kurze Begründung (max. 50 Wörter) für deine Einschätzung geben. Formatiere deine Antwort wie folgt:\n",
    "Sentiment: [positiv/negativ/neutral]\n",
    "Score: [Zahl zwischen 1-10]\n",
    "Begründung: [Deine Erklärung]\"\"\"\n",
    "\n",
    "# Formatierter Prompt\n",
    "formatted_prompt = sentiment_prompt.format(\n",
    "    client_letter=client_letter,\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "print(\"\\nFormatierter Prompt:\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prompt ausführen mit LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "sentiment_chain = sentiment_prompt | llm | StrOutputParser()\n",
    "\n",
    "result = sentiment_chain.invoke({\n",
    "    \"client_letter\": client_letter,\n",
    "    \"format_instructions\": format_instructions\n",
    "})\n",
    "\n",
    "print(\"\\nLLM-Antwort:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenen Prompt im Hub veröffentlichen\n",
    "\n",
    "Um einen eigenen Prompt im LangChain Hub zu veröffentlichen, benötigen Sie einen API-Schlüssel. Hier ist der Prozess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Beispiel: Eigenen Prompt erstellen und auf den Hub hochladen\n",
    "# Hinweis: Erfordert einen API-Schlüssel von LangChain\n",
    "\n",
    "# 1. Erstellen eines eigenen Prompts\n",
    "product_review_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein Experte für Produktbewertungen. \"\n",
    "              \"Analysiere die folgende Produktbewertung und extrahiere wichtige Informationen.\"),\n",
    "    (\"human\", \"{review}\")\n",
    "])\n",
    "\n",
    "# 2. Hochladen zum Hub (nur ausführen, wenn Sie einen API-Schlüssel haben)\n",
    "# hub.push(\"mein_username/product-review-analysis\", product_review_prompt)\n",
    "# print(\"Prompt erfolgreich auf den Hub hochgeladen!\")\n",
    "\n",
    "# Alternativ: Anzeigen, wie der Prompt aussieht\n",
    "print(product_review_prompt.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integration mit Langfuse für Monitoring und Tracking\n",
    "\n",
    "Langfuse ist ein Observability-Tool für LLM-Anwendungen, das Monitoring, Tracing und Evaluation von Prompt-Ausführungen ermöglicht. Die Integration mit LangChain ermöglicht die Überwachung und Optimierung von Prompts im Produktionseinsatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Langfuse-Integration (Kommentiert, da API-Schlüssel erforderlich)\n",
    "\"\"\"\n",
    "# Langfuse initialisieren\n",
    "langfuse = Langfuse(\n",
    "    public_key=os.environ.get(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.environ.get(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=os.environ.get(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    ")\n",
    "\n",
    "# LangChain-Callback-Handler für Langfuse\n",
    "handler = LangfuseCallbackHandler(\n",
    "    public_key=os.environ.get(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    ")\n",
    "\n",
    "# LLM mit Langfuse-Integration\n",
    "llm_with_tracing = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    callbacks=[handler]\n",
    ")\n",
    "\n",
    "# Prompt mit Tracing ausführen\n",
    "chain_with_tracing = product_review_prompt | llm_with_tracing | StrOutputParser()\n",
    "result = chain_with_tracing.invoke({\"review\": \"Ein wirklich tolles Produkt! Sehr empfehlenswert.\"})\n",
    "\"\"\"\n",
    "\n",
    "# Stattdessen zeigen wir, wie Langfuse in einem realen Projekt funktionieren würde\n",
    "print(\"--- Langfuse Integration Demo ---\")\n",
    "print(\"1. Langfuse erstellt automatisch Traces für alle LLM-Aufrufe\")\n",
    "print(\"2. Jede Prompt-Ausführung wird mit Metadaten (Modell, Tokens, Latenz, Kosten) protokolliert\")\n",
    "print(\"3. Sie können Prompts basierend auf Performance-Metriken optimieren\")\n",
    "print(\"4. Feedback-Schleifen ermöglichen kontinuierliche Verbesserung\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: Visualisierung von Langfuse-Daten\n",
    "\n",
    "In der Langfuse-Oberfläche können Sie folgende Informationen einsehen:\n",
    "\n",
    "- Vollständige Traces aller LLM-Interaktionen\n",
    "- Prompt-Performance (Latenz, Token-Nutzung, Kosten)\n",
    "- Modellvergleiche für verschiedene Prompts\n",
    "- Versionierungseffekte auf die Performance\n",
    "\n",
    "![Langfuse Dashboard Beispiel](https://docs.langfuse.com/img/observability/dashboard.png)\n",
    "\n",
    "*(Bild: Beispiel eines Langfuse Dashboards, Quelle: Langfuse Dokumentation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Best Practices für Prompt-Management in Teams\n",
    "\n",
    "### Strukturierung und Namenskonventionen\n",
    "\n",
    "Eine konsistente Struktur für Prompts erleichtert die Wartung und Entwicklung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Beispiel für strukturierte Prompt-Entwicklung\n",
    "\n",
    "# 1. System-Rolle definieren (separat für bessere Wiederverwendbarkeit)\n",
    "customer_service_system = \"\"\"Du bist ein{gender} freundliche{gender} und lösungsorientierte{gender} \n",
    "Kundendienstmitarbeiter{gender} von {company_name}. \n",
    "Du hilfst Kunden bei Problemen mit {product_category}.\n",
    "Wichtige Unternehmensrichtlinien:\n",
    "- {policy1}\n",
    "- {policy2}\n",
    "\"\"\"\n",
    "\n",
    "# 2. Beispiele als Demonstration des gewünschten Verhaltens\n",
    "examples = [\n",
    "    {\"question\": \"Mein Produkt funktioniert nicht mehr\", \n",
    "     \"answer\": \"Es tut mir leid zu hören, dass Sie Probleme mit Ihrem Produkt haben. \"\n",
    "               \"Können Sie mir bitte das genaue Modell und den Fehler beschreiben, \"\n",
    "               \"damit ich Ihnen besser helfen kann?\"},\n",
    "    # Weitere Beispiele...\n",
    "]\n",
    "\n",
    "# 3. Modularer Prompt-Aufbau mit ChatPromptTemplate\n",
    "modular_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", customer_service_system),\n",
    "    (\"human\", \"Hier sind einige Beispiele für gute Antworten: {examples}\"),\n",
    "    (\"human\", \"{customer_query}\")\n",
    "])\n",
    "\n",
    "# 4. Verwendung mit konkreten Werten\n",
    "formatted_modular_prompt = modular_prompt.format(\n",
    "    gender=\"r\",  # für weibliche Form\n",
    "    company_name=\"TechSupport GmbH\",\n",
    "    product_category=\"Elektronikgeräten\",\n",
    "    policy1=\"Rückgabe innerhalb von 14 Tagen ohne Angabe von Gründen möglich\",\n",
    "    policy2=\"Bei Defekten innerhalb der Garantiezeit erfolgt kostenloser Ersatz\",\n",
    "    examples=str(examples),  # Vereinfachte Darstellung für das Beispiel\n",
    "    customer_query=\"Wie kann ich mein defektes Smartphone zurücksenden?\"\n",
    ")\n",
    "\n",
    "print(\"Formatierter modularer Prompt:\")\n",
    "print(formatted_modular_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versionierungs-Workflow in Teams\n",
    "\n",
    "Ein effektiver Workflow für Prompt-Entwicklung im Team umfasst diese Schritte:\n",
    "\n",
    "1. **Entwicklung**: Lokale Iteration und Testing\n",
    "2. **Review**: Peer-Review von Prompt-Änderungen\n",
    "3. **Testing**: Automatisierte Tests für konsistente Ergebnisse\n",
    "4. **Staging**: Testen in einer produktionsähnlichen Umgebung\n",
    "5. **Produktion**: Deployment mit Monitoring\n",
    "6. **Evaluation**: Kontinuierliche Bewertung und Feedback-Sammlung\n",
    "\n",
    "Hier ist ein Beispiel für ein einfaches Testframework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Einfaches Test-Framework für Prompts\n",
    "\n",
    "def test_prompt(prompt_template, test_cases, llm=None):\n",
    "    \"\"\"Test eines Prompts mit mehreren Testfällen\"\"\"\n",
    "    if llm is None:\n",
    "        llm = ChatOpenAI(temperature=0)  # Deterministisches Verhalten für Tests\n",
    "    \n",
    "    results = []\n",
    "    chain = prompt_template | llm | StrOutputParser()\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        try:\n",
    "            # Prompt mit Testdaten ausführen\n",
    "            response = chain.invoke(test_case[\"input\"])\n",
    "            \n",
    "            # Einfache Validierung (kann mit spezifischeren Prüfungen erweitert werden)\n",
    "            validation = {\n",
    "                \"passed\": True,\n",
    "                \"notes\": \"Test bestanden\"\n",
    "            }\n",
    "            \n",
    "            # Wenn expected_contains definiert ist, prüfen ob es in der Antwort enthalten ist\n",
    "            if \"expected_contains\" in test_case:\n",
    "                for expected in test_case[\"expected_contains\"]:\n",
    "                    if expected.lower() not in response.lower():\n",
    "                        validation[\"passed\"] = False\n",
    "                        validation[\"notes\"] = f\"Erwarteter Text nicht gefunden: {expected}\"\n",
    "            \n",
    "            # Wenn expected_format definiert ist (z.B. JSON), Format überprüfen\n",
    "            if \"expected_format\" in test_case and test_case[\"expected_format\"] == \"json\":\n",
    "                try:\n",
    "                    json.loads(response)\n",
    "                except json.JSONDecodeError:\n",
    "                    validation[\"passed\"] = False\n",
    "                    validation[\"notes\"] = \"Antwort ist kein gültiges JSON\"\n",
    "            \n",
    "            results.append({\n",
    "                \"test_case\": i + 1,\n",
    "                \"input\": test_case[\"input\"],\n",
    "                \"response\": response,\n",
    "                \"validation\": validation\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"test_case\": i + 1,\n",
    "                \"input\": test_case[\"input\"],\n",
    "                \"error\": str(e),\n",
    "                \"validation\": {\"passed\": False, \"notes\": f\"Fehler bei der Ausführung: {e}\"}\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Beispiel: Prompt-Tests durchführen\n",
    "\n",
    "# Einfacher Testprompt für Produktbeschreibungen\n",
    "product_desc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein Produktbeschreibungs-Generator für einen Online-Shop. \"\n",
    "              \"Erstelle eine kurze, überzeugende Beschreibung für das folgende Produkt.\"),\n",
    "    (\"human\", \"Produkt: {product_name}\\nKategorie: {category}\\nHauptmerkmale: {features}\")\n",
    "])\n",
    "\n",
    "# Testfälle definieren\n",
    "test_cases = [\n",
    "    {\n",
    "        \"input\": {\n",
    "            \"product_name\": \"Wireless Kopfhörer XZ-500\",\n",
    "            \"category\": \"Audio\",\n",
    "            \"features\": \"Bluetooth 5.0, 30h Akkulaufzeit, Noise-Cancelling\"\n",
    "        },\n",
    "        \"expected_contains\": [\"Kopfhörer\", \"Akku\", \"Noise\"]\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\n",
    "            \"product_name\": \"Ergonomische Bürotastatur K-2000\",\n",
    "            \"category\": \"Computer-Zubehör\",\n",
    "            \"features\": \"Mechanische Switches, RGB-Beleuchtung, Handballenauflage\"\n",
    "        },\n",
    "        \"expected_contains\": [\"Tastatur\", \"ergonomisch\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Tests ausführen\n",
    "test_results = test_prompt(product_desc_prompt, test_cases)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "for result in test_results:\n",
    "    print(f\"\\nTestfall {result['test_case']}:\")\n",
    "    print(f\"Status: {'✅ Bestanden' if result['validation']['passed'] else '❌ Fehlgeschlagen'}\")\n",
    "    print(f\"Notizen: {result['validation']['notes']}\")\n",
    "    print(f\"Antwort: {result['response'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Zusammenfassung: Best Practices für Prompt-Management\n",
    "\n",
    "1. **Strukturierung und Modularität**\n",
    "   - Prompts in wiederverwendbare Komponenten aufteilen\n",
    "   - Klare Namenskonventionen verwenden\n",
    "   - Metadaten für Kontext und Nutzung hinzufügen\n",
    "\n",
    "2. **Versionierung**\n",
    "   - Jede Version eindeutig identifizierbar machen\n",
    "   - Änderungshistorie dokumentieren\n",
    "   - A/B-Testing für neue Versionen durchführen\n",
    "\n",
    "3. **Zusammenarbeit**\n",
    "   - Zentrale Repositories wie LangChain Hub nutzen\n",
    "   - Review-Prozesse implementieren\n",
    "   - Dokumentation für jede Prompt-Familie führen\n",
    "\n",
    "4. **Testing und Evaluation**\n",
    "   - Automatisierte Tests mit erwarteten Ergebnissen\n",
    "   - Unterschiedliche Eingabeszenarien abdecken\n",
    "   - Edge Cases berücksichtigen\n",
    "\n",
    "5. **Monitoring und Optimierung**\n",
    "   - Tools wie Langfuse für Observability einsetzen\n",
    "   - Performance-Metriken verfolgen (Latenz, Token, Kosten)\n",
    "   - Nutzer-Feedback systematisch erfassen und einbeziehen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übungsaufgaben\n",
    "\n",
    "1. Erstellen Sie einen parametrisierten Prompt für einen bestimmten Anwendungsfall (z.B. Produkt-Rezensionen, Support-Anfragen)\n",
    "2. Implementieren Sie eine lokale Prompt-Versionierung mit dem PromptManager\n",
    "3. Testen Sie Ihren Prompt mit verschiedenen Eingabeszenarien\n",
    "4. Erstellen Sie eine verbesserte Version Ihres Prompts und vergleichen Sie die Ergebnisse\n",
    "5. (Optional) Veröffentlichen Sie Ihren Prompt im LangChain Hub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
