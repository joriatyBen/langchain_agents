{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell-Typen im Überblick\n",
    "\n",
    "In diesem Notebook lernen wir verschiedene Typen von Large Language Models (LLMs) kennen und erkunden ihre spezifischen Eigenschaften und Anwendungsfälle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LLM-Modelle im Vergleich\n",
    "\n",
    "Wir beginnen mit einem Überblick der gängigsten LLM-Modelle und ihrer Eigenschaften."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import llm\n",
    "import time\n",
    "\n",
    "# Standard-Modell ist gpt-4o\n",
    "standard_model = llm()\n",
    "\n",
    "# Verschiedene Modelle im Vergleich\n",
    "models = {\n",
    "    \"gpt-3.5-turbo\": llm(model=\"gpt-3.5-turbo\"),\n",
    "    \"gpt-4o\": llm(model=\"gpt-4o\"),\n",
    "    \"gpt-4o-mini\": llm(model=\"gpt-4o-mini\"),\n",
    "}\n",
    "\n",
    "test_prompt = \"Erkläre mir das Konzept einer rekursiven Funktion in 2-3 Sätzen.\"\n",
    "\n",
    "# Vergleich von Antwortzeiten und Qualität\n",
    "for model_name, model_instance in models.items():\n",
    "    print(f\"\\n--- Modell: {model_name} ---\")\n",
    "    start_time = time.time()\n",
    "    response = model_instance.invoke(test_prompt)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Antwort: {response.content}\")\n",
    "    print(f\"Dauer: {end_time - start_time:.2f} Sekunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embeddings: Grundlagen und Anwendungen\n",
    "\n",
    "Embeddings sind numerische Vektorrepräsentationen von Text, Bildern oder anderen Daten. Sie bilden semantische Eigenschaften in einem mehrdimensionalen Raum ab und sind fundamental für viele KI-Anwendungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Tokenisierung verstehen\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "example_text = \"Künstliche Intelligenz verändert die Welt.\"\n",
    "tokens = encoding.encode(example_text)\n",
    "print(f\"Text: '{example_text}'\")\n",
    "print(f\"Token-IDs: {tokens}\")\n",
    "\n",
    "# Jeder Token einzeln dekodiert\n",
    "decoded_tokens = [encoding.decode_single_token_bytes(token).decode(\"utf-8\") for token in tokens]\n",
    "print(\"\\nToken für Token:\")\n",
    "for i, token in enumerate(decoded_tokens):\n",
    "    print(f\"Token {i+1}: '{token}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings mit OpenAI erzeugen und vergleichen\n",
    "\n",
    "Embeddings ermöglichen es uns, semantische Ähnlichkeiten zwischen Texten zu berechnen. Wir werden einige Beispielsätze vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Embeddings für verschiedene Sätze berechnen\n",
    "texts = [\n",
    "    \"Künstliche Intelligenz verändert die Welt\",\n",
    "    \"KI revolutioniert alle Wirtschaftsbereiche\",\n",
    "    \"Machine Learning ist ein Teilbereich der Künstlichen Intelligenz\",\n",
    "    \"Katzen sind niedliche Haustiere\",\n",
    "    \"Hunde werden oft als treue Begleiter bezeichnet\",\n",
    "    \"Tiere spielen eine wichtige Rolle im Ökosystem\",\n",
    "]\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=texts,\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# Embeddings extrahieren\n",
    "embeddings = [np.array(item.embedding) for item in response.data]\n",
    "\n",
    "# Cosinus-Ähnlichkeit berechnen\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Ähnlichkeitsmatrix erstellen\n",
    "similarity_matrix = np.zeros((len(texts), len(texts)))\n",
    "for i in range(len(texts)):\n",
    "    for j in range(len(texts)):\n",
    "        similarity_matrix[i, j] = cosine_similarity(embeddings[i], embeddings[j])\n",
    "\n",
    "# Visualisierung der Ähnlichkeitsmatrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(similarity_matrix, cmap='viridis')\n",
    "plt.colorbar(label='Cosinus-Ähnlichkeit')\n",
    "plt.xticks(range(len(texts)), [f\"Text {i+1}\" for i in range(len(texts))], rotation=45)\n",
    "plt.yticks(range(len(texts)), [f\"Text {i+1}\" for i in range(len(texts))])\n",
    "plt.title('Semantische Ähnlichkeit zwischen Texten')\n",
    "\n",
    "# Beschriftung für die Texte\n",
    "for i in range(len(texts)):\n",
    "    print(f\"Text {i+1}: {texts[i]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualisierung mit PCA für 2D-Darstellung\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], s=100)\n",
    "\n",
    "for i, (x, y) in enumerate(reduced_embeddings):\n",
    "    plt.annotate(f\"Text {i+1}\", (x, y), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.title('2D-Visualisierung der Embeddings')\n",
    "plt.xlabel('Erste Hauptkomponente')\n",
    "plt.ylabel('Zweite Hauptkomponente')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multimodale Modelle: Text und Bild\n",
    "\n",
    "Multimodale Modelle können verschiedene Arten von Eingaben (Text, Bild, Audio) verarbeiten und miteinander verknüpfen. Hier ein Beispiel für die Arbeit mit Bildern in GPT-4o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# GPT-4o als multimodales Modell verwenden\n",
    "vision_llm = llm(model=\"gpt-4o\", max_tokens=1024)\n",
    "\n",
    "# Beispiel: Bildanalyse mit einem Comic\n",
    "input = [\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            \"Was ist auf diesem Bild zu sehen? Erkläre auch den Witz dahinter.\",\n",
    "            {\"image_url\": \"https://joscha.com/data/media/cartoons/130608.png\"},\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "response = vision_llm.invoke(input)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praktische Anwendung: Bild generieren und analysieren\n",
    "\n",
    "Wir kombinieren nun Text-zu-Bild-Generierung mit Bildanalyse, um den vollständigen multimodalen Kreislauf zu demonstrieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from IPython.display import Image, display\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# 1. Prompt für die Bildgenerierung erstellen\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"Generiere einen präzisen Prompt für DALL-E, um ein Bild zu erzeugen, das folgendes Konzept visualisiert: {image_desc}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 2. Chain für die Prompt-Optimierung\n",
    "chain = prompt | llm(temperature=0.7) | StrOutputParser()\n",
    "\n",
    "# 3. Nutzereingabe für das Bild\n",
    "user_image_description = \"Ein Roboter, der in einer Bibliothek sitzt und Bücher liest, während er gleichzeitig neue Bücher schreibt\"\n",
    "\n",
    "# 4. Optimierten Prompt generieren\n",
    "dalle_prompt = chain.invoke({\"image_desc\": user_image_description})\n",
    "print(f\"Optimierter DALL-E Prompt:\\n{dalle_prompt}\\n\")\n",
    "\n",
    "# 5. Bild mit DALL-E generieren\n",
    "try:\n",
    "    image_url = DallEAPIWrapper(model=\"dall-e-2\", size=\"1024x1024\").run(dalle_prompt)\n",
    "    print(f\"Generiertes Bild: {image_url}\")\n",
    "    \n",
    "    # Bild herunterladen und anzeigen\n",
    "    response = requests.get(image_url)\n",
    "    img = Image(data=response.content)\n",
    "    display(img)\n",
    "    \n",
    "    # 6. Bild mit GPT-4o analysieren\n",
    "    vision_input = [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                \"Beschreibe detailliert, was auf diesem Bild zu sehen ist. Wie gut repräsentiert es das Konzept: '\" + user_image_description + \"'?\",\n",
    "                {\"image_url\": image_url},\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    vision_response = vision_llm.invoke(vision_input)\n",
    "    print(\"\\nAnalyse des generierten Bildes:\")\n",
    "    print(vision_response.content)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fehler bei der Bildgenerierung oder -analyse: {e}\")\n",
    "    print(\"Um diesen Teil auszuführen, stellen Sie sicher, dass Sie einen gültigen DALL-E API-Schlüssel haben.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reranker für verbesserte Textsuche (optionales Thema)\n",
    "\n",
    "Reranker verbessern die Qualität von Suchergebnissen durch eine präzisere Bewertung der Relevanz zwischen einer Anfrage und potenziellen Dokumenten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel-Code für Reranking mit Sentence Transformers\n",
    "# Wenn Sie diesen Code ausführen möchten, installieren Sie: pip install sentence-transformers\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import CrossEncoder\n",
    "    \n",
    "    # Beispiel-Dokumente\n",
    "    documents = [\n",
    "        \"Berlin ist die Hauptstadt von Deutschland und hat etwa 3,7 Millionen Einwohner.\",\n",
    "        \"Paris ist die Hauptstadt von Frankreich und ein beliebtes Reiseziel.\",\n",
    "        \"Der Fluss Spree fließt durch Berlin und ist wichtig für die Stadt.\",\n",
    "        \"Berlin hat viele Sehenswürdigkeiten wie das Brandenburger Tor.\",\n",
    "        \"Deutschland grenzt an neun Nachbarländer in Europa.\"\n",
    "    ]\n",
    "    \n",
    "    # Abfrage\n",
    "    query = \"Was ist die Hauptstadt von Deutschland?\"\n",
    "    \n",
    "    print(\"Abfrage:\", query)\n",
    "    print(\"\\nDokumente ohne Ranking:\")\n",
    "    for i, doc in enumerate(documents):\n",
    "        print(f\"{i+1}. {doc}\")\n",
    "    \n",
    "    # Reranking mit einem Cross-Encoder\n",
    "    reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    pairs = [[query, doc] for doc in documents]\n",
    "    scores = reranker.predict(pairs)\n",
    "    \n",
    "    # Ergebnisse sortieren\n",
    "    ranked_results = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nDokumente nach Reranking:\")\n",
    "    for i, (doc, score) in enumerate(ranked_results):\n",
    "        print(f\"{i+1}. Score: {score:.4f} - {doc}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Sentence Transformers nicht installiert. Bitte führen Sie 'pip install sentence-transformers' aus, um dieses Beispiel zu nutzen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modellauswahl in der Praxis\n",
    "\n",
    "Lassen Sie uns das LLM selbst nach Entscheidungskriterien für die Modellauswahl fragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "# Prompt für Modellauswahl-Empfehlungen\n",
    "model_selection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Du bist ein erfahrener KI-Architekt, der Teams bei der Auswahl des richtigen LLM-Modells für ihre Anwendungen berät.\"),\n",
    "    (\"human\", \"\"\"\n",
    "    Erstelle eine Entscheidungsmatrix für folgende Anwendungsfälle und empfehle das optimale Modell:\n",
    "    \n",
    "    1. Ein Chatbot für einfache Kundenanfragen auf einer E-Commerce-Website\n",
    "    2. Ein System zur Analyse und Zusammenfassung wissenschaftlicher Fachartikel\n",
    "    3. Eine Anwendung zur Analyse von Röntgenbildern mit begleitendem Befundtext\n",
    "    4. Ein Tool für die automatische Codegenerierung für Entwickler\n",
    "    5. Ein Übersetzungssystem für juristische Texte, das in einer Bank ohne Internetverbindung laufen soll\n",
    "    \n",
    "    Berücksichtige folgende Faktoren: Kosten, Leistung, Datenschutz, Multimodale Fähigkeiten und Integrationsaufwand.\n",
    "    Strukturiere deine Antwort übersichtlich in Tabellenform und füge eine kurze Begründung für jede Empfehlung hinzu.\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "model_selection_chain = model_selection_prompt | llm() | StrOutputParser()\n",
    "response = model_selection_chain.invoke({})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Praktische Übungen\n",
    "\n",
    "### Übung 1: Token-Analyse\n",
    "Analysieren Sie, wie verschiedene Texte in Tokens zerlegt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tokens(text):\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "    tokens = encoding.encode(text)\n",
    "    decoded_tokens = [encoding.decode_single_token_bytes(token).decode(\"utf-8\") for token in tokens]\n",
    "    \n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Anzahl Tokens: {len(tokens)}\")\n",
    "    print(\"Tokens:\")\n",
    "    for i, token in enumerate(decoded_tokens):\n",
    "        print(f\"  {i+1}: '{token}'\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Beispiel\n",
    "analyze_tokens(\"Künstliche Intelligenz ist faszinierend!\")\n",
    "\n",
    "# Übung: Analysieren Sie verschiedene Texte\n",
    "# Beispiel 1: Fachbegriffe\n",
    "analyze_tokens(\"Machine Learning und Deep Learning sind Teilbereiche der KI.\")\n",
    "\n",
    "# Beispiel 2: Sonderzeichen und Zahlen\n",
    "analyze_tokens(\"Das kostet 123,45€ und ist verfügbar ab dem 01.01.2023!\")\n",
    "\n",
    "# Beispiel 3: Eigener Text (hier einfügen)\n",
    "# analyze_tokens(\"Ihr eigener Text hier...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Übung 2: Embedding-Vergleich verschiedener Konzepte\n",
    "\n",
    "Erstellen Sie Embeddings für verschiedene Konzepte und vergleichen Sie die Ähnlichkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Texte für Embedding-Vergleich definieren\n",
    "your_texts = [\n",
    "    # Fügen Sie hier 4-6 verschiedene Texte oder Konzepte ein\n",
    "    # Beispiel:\n",
    "    \"Maschinelles Lernen ist ein Teilgebiet der künstlichen Intelligenz\",\n",
    "    \"Data Science umfasst Statistik, Programmierung und Domänenwissen\",\n",
    "    \"Python ist eine beliebte Programmiersprache für KI-Anwendungen\",\n",
    "    \"Neuronale Netze sind vom menschlichen Gehirn inspiriert\",\n",
    "    # Fügen Sie weitere Texte hinzu...\n",
    "]\n",
    "\n",
    "# Embeddings berechnen (wenn OpenAI API verfügbar ist)\n",
    "try:\n",
    "    response = client.embeddings.create(\n",
    "        input=your_texts,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    \n",
    "    embeddings = [np.array(item.embedding) for item in response.data]\n",
    "    \n",
    "    # Ähnlichkeitsmatrix\n",
    "    similarity_matrix = np.zeros((len(your_texts), len(your_texts)))\n",
    "    for i in range(len(your_texts)):\n",
    "        for j in range(len(your_texts)):\n",
    "            similarity_matrix[i, j] = cosine_similarity(embeddings[i], embeddings[j])\n",
    "    \n",
    "    # Visualisierung\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(similarity_matrix, cmap='viridis')\n",
    "    plt.colorbar(label='Cosinus-Ähnlichkeit')\n",
    "    plt.xticks(range(len(your_texts)), [f\"Text {i+1}\" for i in range(len(your_texts))], rotation=45)\n",
    "    plt.yticks(range(len(your_texts)), [f\"Text {i+1}\" for i in range(len(your_texts))])\n",
    "    plt.title('Ihre semantische Ähnlichkeitsmatrix')\n",
    "    \n",
    "    # Textbeschreibungen\n",
    "    for i, text in enumerate(your_texts):\n",
    "        print(f\"Text {i+1}: {text}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fehler bei der Embedding-Berechnung: {e}\")\n",
    "    print(\"Stellen Sie sicher, dass die OpenAI API korrekt konfiguriert ist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Zusammenfassung\n",
    "\n",
    "In diesem Notebook haben wir folgende Konzepte kennengelernt:\n",
    "\n",
    "1. **Verschiedene LLM-Modelle** und ihre spezifischen Stärken und Schwächen\n",
    "2. **Embeddings** als Vektorrepräsentationen von Text und ihre Anwendungen in semantischer Suche\n",
    "3. **Multimodale Modelle** wie GPT-4o, die Text und Bilder verarbeiten können\n",
    "4. **Reranker** zur Verbesserung von Suchergebnissen (optionales Thema)\n",
    "5. **Praktische Entscheidungskriterien** für die Modellauswahl in realen Projekten\n",
    "\n",
    "Diese Grundlagen bilden die Basis für fortgeschrittene KI-Anwendungen und geben einen Überblick über die vielfältigen Möglichkeiten moderner LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}