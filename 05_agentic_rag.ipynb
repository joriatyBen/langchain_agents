{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## ü¶úüîó LangChain RAG Agent (RAG nur bei Bedarf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from helpers import llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### In diesem Notebook schauen wir uns an, wie RAG als Tool funktioniert.\n",
    "\n",
    "Es wird also nicht einfach auf gut Gl√ºck bei jeder Anfrage das RAG angeworfen und Dokumente mit in die Prompt geh√§ngt. Das entscheidet unser Agent nun alleine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Wir erstellen eine kleine in-memory FAISS Datenbank.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "loader = PyPDFLoader(\"LangChain.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=80, chunk_overlap=30)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Wir benutzen LangChain-Magie um aus der Vektor-Datenbank ein Tool zu machen, das der Agent benutzen kann\n",
    "\n",
    "Die Beschreibung \"This is the best place to look for any information about LangChain.\" ist essentiell f√ºr die Funktionalit√§t der gesamten App. Damit wei√ü das LLM, dass es genau dieses Tool aufrufen muss, wenn es Informationen zu LangChain braucht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_langchain_documentation\",\n",
    "    \"This is the best place to look for any information about LangChain.\",\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Wir bauen den Agenten mit Hilfe von LangGraph prebuilt und geben ihm das Tool.\n",
    "\n",
    "Das Prompt ziehen wir vom Hub. Es ist nicht sonderlich relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e6e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage\n",
    "\n",
    "system_message = SystemMessage(content=\"Du bist ein hilfsbereiter Assistent.\")\n",
    "agent_executor = create_react_agent(llm(), tools, state_modifier=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b0cc7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"messages\": [HumanMessage(content=\"Wie nutze ich Langchain mit einem Vectorstore?\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Wie nutze ich Langchain mit einem Vectorstore?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_langchain_documentation (call_W2nWgVMYuC1CFLSB4jSf2AMP)\n",
      " Call ID: call_W2nWgVMYuC1CFLSB4jSf2AMP\n",
      "  Args:\n",
      "    query: Langchain mit Vectorstore\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_langchain_documentation\n",
      "\n",
      "GettingStartedWithLangChain 20\n",
      "LangChain Overview Wrap Up\n",
      "WewillcontinueusingLangChainfortherestofthisbookaswell\n",
      "astheLlamaIndexlibrarythatweintroduceinthenextchapter.\n",
      "IcoverjustthesubsetofLangChainthatIuseinmyownprojects\n",
      "in this book. I urge you to read the LangChain documentation\n",
      "andtoexplorepublicLangChainchainsthatusershavewrittenon\n",
      "Langchain-hub5.\n",
      "5https://github.com/hwchase17/langchain-hub\n",
      "\n",
      "GettingStartedWithLangChain 10\n",
      "foragents,alibraryofagentstochoosefrom,andexamplesofend-\n",
      "to-endagents.\n",
      "LangChainMemoryistheconceptofpersistingstatebetweencalls\n",
      "of a chain or agent. LangChain provides a standard interface for\n",
      "memory, a collection of memory implementations, and examples\n",
      "of chains/agents that use memory¬≤. LangChain provides a large\n",
      "collection of common utils to use in your application. Chains go\n",
      "beyondjustasingleLLMcall, andaresequencesofcalls(whether\n",
      "to an LLM or a different utility). LangChain provides a standard\n",
      "interface for chains, lots of integrations with other tools, and end-\n",
      "to-endchainsforcommonapplications.\n",
      "LangChain can be integrated with one or more model providers,\n",
      "data stores, APIs, etc. LangChain can be used for in-depth\n",
      "question-and-answer chat sessions, API interaction, or action-\n",
      "taking. LangChain can be integrated with Zapier‚Äôs platform\n",
      "through a natural language API interface (we have an entire\n",
      "chapterdedicatedtoZapierintegrations).\n",
      "Installing Necessary Packages\n",
      "Forthepurposesofexamplesinthisbook,youmightwanttocreate\n",
      "anewAnacondaorotherPythonenvironmentandinstall:\n",
      "1pip install langchain llama_index openai\n",
      "2pip install kor pydrive pandas rdflib\n",
      "3pip install google-search-results SPARQLWrapper\n",
      "Fortherestofthischapterwewillusethesubdirectory langchain_-\n",
      "getting_started and in the next chapter use llama-index_case_-\n",
      "studyintheGitHubrepositoryforthisbook.\n",
      "\n",
      "GettingStartedWithLangChain 17\n",
      "is the embeddings for one input text document. The query_-\n",
      "embedding is a single embedding. Please read the above linked\n",
      "embeddingdocumentation.\n",
      "Wewillusevectorstorestostorecalculatedembeddingsforfuture\n",
      "use. In the next chapter we will see a document database search\n",
      "exampleusingLangChainandLlama-Index.\n",
      "Using LangChain Vector Stores to\n",
      "Query Documents\n",
      "We will reference the LangChain Vector Stores documentation4.\n",
      "Youneedtoinstallafewlibraries:\n",
      "1pip install chroma\n",
      "2pip install chromadb\n",
      "3pip install unstructured pdf2image pytesseract\n",
      "Theexamplescriptis doc_search.py :\n",
      "1from langchain .text_splitter import CharacterTextSplitter\n",
      "2from langchain .vectorstores import Chroma\n",
      "3from langchain .embeddings import OpenAIEmbeddings\n",
      "4from langchain .document_loaders import DirectoryLoader\n",
      "5from langchain import OpenAI, VectorDBQA\n",
      "6\n",
      "7embeddings =OpenAIEmbeddings()\n",
      "8\n",
      "9loader =DirectoryLoader( '../data/ ', glob =\"**/*.txt \")\n",
      "10 documents =loader .load()\n",
      "11 text_splitter =CharacterTextSplitter(chunk_size =2500 , ch\\\n",
      "12 unk_overlap =0)\n",
      "4https://python.langchain.com/en/latest/reference/modules/vectorstore.html\n",
      "\n",
      "Getting Started With\n",
      "LangChain\n",
      "Harrison Chase started the LangChain project in October 2022\n",
      "and as I write this book in February 2023 the GitHub repository\n",
      "for LangChain https://github.com/hwchase17/langchain has 171\n",
      "contributors.\n",
      "LangChain1is a framework for building applications with large\n",
      "language models (LLMs) through chaining different components\n",
      "together. Some of the applications of LangChain are chatbots,\n",
      "generative question-answering, summarization, data-augmented\n",
      "generation and more. LangChain can save time in building chat-\n",
      "botsandothersystemsbyprovidingastandardinterfaceforchains,\n",
      "agents and memory, as well as integrations with other tools and\n",
      "end-to-end examples. We refer to ‚Äúchains‚Äù as sequences of calls\n",
      "(to an LLMs and a different program utilities, cloud services, etc.)\n",
      "that go beyond just one LLM API call. LangChain provides a\n",
      "standard interface for chains, many integrations with other tools,\n",
      "and end-to-end chains for common applications. Often you will\n",
      "findexistingchainsalreadywrittenthatmeettherequirementsfor\n",
      "yourapplications.\n",
      "For example, one can create a chain that takes user input, formats\n",
      "itusingaPromptTemplate,andthenpassestheformattedresponse\n",
      "toaLargeLanguageModel(LLM)forprocessing.\n",
      "WhileLLMsareverygeneralinnaturewhichmeansthatwhilethey\n",
      "canperformmanytaskseffectively,theyoftencannotdirectlypro-\n",
      "videspecificanswerstoquestionsortasksthatrequiredeepdomain\n",
      "knowledge or expertise. LangChain provides a standard interface\n",
      "1https://langchain.readthedocs.io/en/latest/index.html\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Um LangChain mit einem Vectorstore zu nutzen, folgen Sie diesen Schritten:\n",
      "\n",
      "1. **Installation der notwendigen Pakete**: Zuerst m√ºssen Sie die erforderlichen Bibliotheken installieren. Sie k√∂nnen dies mit folgendem Befehl tun:\n",
      "\n",
      "   ```bash\n",
      "   pip install langchain llama_index openai\n",
      "   pip install chroma chromadb unstructured pdf2image pytesseract\n",
      "   ```\n",
      "\n",
      "2. **Importieren der ben√∂tigten Module**: In Ihrem Python-Skript m√ºssen Sie die notwendigen Module importieren. Hier ist ein Beispiel:\n",
      "\n",
      "   ```python\n",
      "   from langchain.text_splitter import CharacterTextSplitter\n",
      "   from langchain.vectorstores import Chroma\n",
      "   from langchain.embeddings import OpenAIEmbeddings\n",
      "   from langchain.document_loaders import DirectoryLoader\n",
      "   from langchain import OpenAI, VectorDBQA\n",
      "   ```\n",
      "\n",
      "3. **Erstellen von Embeddings**: Sie m√ºssen Embeddings f√ºr Ihre Dokumente erstellen. Hier ist ein Beispiel, wie Sie das tun k√∂nnen:\n",
      "\n",
      "   ```python\n",
      "   embeddings = OpenAIEmbeddings()\n",
      "   ```\n",
      "\n",
      "4. **Laden der Dokumente**: Verwenden Sie einen Dokumentenloader, um Ihre Texte zu laden. Zum Beispiel:\n",
      "\n",
      "   ```python\n",
      "   loader = DirectoryLoader('../data/', glob=\"**/*.txt\")\n",
      "   documents = loader.load()\n",
      "   ```\n",
      "\n",
      "5. **Textaufteilung**: Teilen Sie die Dokumente in kleinere Teile auf, um die Verarbeitung zu erleichtern:\n",
      "\n",
      "   ```python\n",
      "   text_splitter = CharacterTextSplitter(chunk_size=2500, chunk_overlap=0)\n",
      "   split_documents = text_splitter.split_documents(documents)\n",
      "   ```\n",
      "\n",
      "6. **Speichern der Embeddings in einem Vectorstore**: Sie k√∂nnen nun die Embeddings in einem Vectorstore wie Chroma speichern.\n",
      "\n",
      "7. **Abfragen der Dokumente**: Verwenden Sie den Vectorstore, um Abfragen durchzuf√ºhren und relevante Dokumente zu finden.\n",
      "\n",
      "Durch diese Schritte k√∂nnen Sie LangChain effektiv mit einem Vectorstore nutzen, um Dokumente zu verarbeiten und Abfragen durchzuf√ºhren. Weitere Details finden Sie in der [LangChain-Dokumentation](https://python.langchain.com/en/latest/reference/modules/vectorstore.html).\n"
     ]
    }
   ],
   "source": [
    "for event in agent_executor.stream(input, stream_mode=\"values\"):\n",
    "    message: BaseMessage = event[\"messages\"][-1]\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Echtes Streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um LangChain mit einem Vectorstore zu nutzen, folgen Sie diesen grundlegenden Schritten:\n",
      "\n",
      "1. **Installation der erforderlichen Bibliotheken**:\n",
      "   Sie m√ºssen einige Pakete installieren, um mit Vectorstores arbeiten zu k√∂nnen. F√ºhren Sie die folgenden Befehle in Ihrer Kommandozeile aus:\n",
      "   ```bash\n",
      "   pip install langchain chroma chromadb unstructured pdf2image pytesseract\n",
      "   ```\n",
      "\n",
      "2. **Importieren der notwendigen Module**:\n",
      "   In Ihrem Python-Skript importieren Sie die erforderlichen Module:\n",
      "   ```python\n",
      "   from langchain.text_splitter import CharacterTextSplitter\n",
      "   from langchain.vectorstores import Chroma\n",
      "   from langchain.embeddings import OpenAIEmbeddings\n",
      "   from langchain.document_loaders import DirectoryLoader\n",
      "   from langchain import OpenAI, VectorDBQA\n",
      "   ```\n",
      "\n",
      "3. **Erstellen von Embeddings**:\n",
      "   Sie m√ºssen ein Embedding-Modell erstellen, um Textdokumente in Vektoren umzuwandeln. Beispielsweise:\n",
      "   ```python\n",
      "   embeddings = OpenAIEmbeddings()\n",
      "   ```\n",
      "\n",
      "4. **Laden von Dokumenten**:\n",
      "   Laden Sie die Dokumente, die Sie indizieren m√∂chten. Zum Beispiel aus einem Verzeichnis:\n",
      "   ```python\n",
      "   loader = DirectoryLoader('../data/', glob=\"**/*.txt\")\n",
      "   documents = loader.load()\n",
      "   ```\n",
      "\n",
      "5. **Text aufteilen**:\n",
      "   Teilen Sie die Dokumente in kleinere Abschnitte, um die Verarbeitung zu erleichtern:\n",
      "   ```python\n",
      "   text_splitter = CharacterTextSplitter(chunk_size=2500, chunk_overlap=0)\n",
      "   split_documents = text_splitter.split_documents(documents)\n",
      "   ```\n",
      "\n",
      "6. **Erstellen des Vectorstores**:\n",
      "   Erstellen Sie den Vectorstore mit den geladenen Embeddings:\n",
      "   ```python\n",
      "   vectorstore = Chroma.from_documents(split_documents, embeddings)\n",
      "   ```\n",
      "\n",
      "7. **Durchf√ºhren von Abfragen**:\n",
      "   Verwenden Sie den Vectorstore, um Abfragen durchzuf√ºhren. Sie k√∂nnen beispielsweise `VectorDBQA` verwenden, um Fragen zu den Dokumenten zu stellen:\n",
      "   ```python\n",
      "   qa = VectorDBQA(vectorstore=vectorstore)\n",
      "   response = qa({\"query\": \"Ihre Frage hier\"})\n",
      "   print(response)\n",
      "   ```\n",
      "\n",
      "Diese Schritte bieten eine grundlegende Anleitung zur Verwendung von LangChain mit einem Vectorstore. Weitere Details und spezifische Anpassungen finden Sie in der [LangChain-Dokumentation](https://python.langchain.com)."
     ]
    }
   ],
   "source": [
    "from helpers import graph_agent_llm_output_streamer_events\n",
    "\n",
    "await graph_agent_llm_output_streamer_events(agent_executor, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7d082",
   "metadata": {},
   "source": [
    "## ‚úÖ Aufgabe\n",
    "\n",
    "In der Datei \"LLMAll_de-DE.md\" findet sich die deutsche Version der OWASP Top 10 f√ºr LLMs.\n",
    "Erweitere den Agent so, dass er hier f√ºr Sicherheitsfragen nachschaut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "secloader = UnstructuredMarkdownLoader(\n",
    "    \"LLMAll_de-DE.md\",\n",
    "    mode=\"elements\",\n",
    "    strategy=\"fast\",\n",
    ")\n",
    "\n",
    "# Load, split and index the documents\n",
    "# and create a tool named \"sectool\" based on the retriever\n",
    "\n",
    "tools = [sectool, tool]\n",
    "\n",
    "system_message = SystemMessage(content=\"Du bist ein hilfsbereiter Assistent.\")\n",
    "agent_executor = create_react_agent(llm(), tools, system_message)\n",
    "\n",
    "input = {\"messages\": [HumanMessage(content=\"Warum sind Prompt Injections gef√§hrlich?\")]}\n",
    "\n",
    "\n",
    "await graph_agent_llm_output_streamer_events(agent_executor, input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
