{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## ü¶úüîó Langgraph Agenten, die vor Toolbenutzung nachfragen und Checkpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Manchmal m√∂chte man, dass ein Agent etwas tun darf, aber nur nach R√ºckfrage. Typisch Anwendungsf√§lle sind z.B. Email-Versand oder der Zugriff auf das Betriebssystem.\n",
    "\n",
    "In diesem Notebook wollen wir zwei M√∂glichkeiten untersuchen, dies zu tun.\n",
    "\n",
    "- Naiver Ansatz. Wir bauen ein Terminalprompt ein. Und zwar im Codefluss genau vor der Stelle, wo die Anwendung kritische Berechtigungen braucht.\n",
    "- L√∂sung mit LangGraph-Checkpoints. Dieser Teil ist z.T. sehr detailreich. Man muss sich wirklich nicht alles davon merken.\n",
    "\n",
    "### L√∂sung 1. Mit einem Terminalprompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.shell import ShellTool\n",
    "from helpers import llm\n",
    "\n",
    "tools = [ShellTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Wenn das Tool \"terminal\" aufgerufen wird, soll es mit einer Nutzerabfrage best√§tigt werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import chain\n",
    "from langgraph.graph import END\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "@chain\n",
    "def tool_executor(tool_call):\n",
    "    tool = {tool.name: tool for tool in tools}[tool_call[\"name\"]]\n",
    "    return ToolMessage(\n",
    "        tool.invoke(tool_call[\"args\"]),\n",
    "        tool_call_id=tool_call[\"id\"],\n",
    "        name=tool_call[\"name\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm(model=\"gpt-4o\").bind_tools(tools).invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def call_tools(state):\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    response = []\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call[\"name\"] == \"terminal\":\n",
    "            feedback = input(\n",
    "                prompt=f\"[y/n] continue with shell execution: {tool_call['args']['commands']}?\"\n",
    "            )\n",
    "            if feedback == \"y\":\n",
    "                response.append(tool_executor.invoke(tool_call))\n",
    "            else:\n",
    "                output = \"Your terminal command was not permitted by the user. Try a different terminal command or return unfinished.\"\n",
    "                response.append(\n",
    "                    ToolMessage(\n",
    "                        output, tool_call_id=tool_call[\"id\"], name=tool_call[\"name\"]\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            response.append(tool_executor.invoke(tool_call))\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "def should_continue(state) -> Literal[\"call_tools\", END]:  # type: ignore\n",
    "    return \"call_tools\" if state[\"messages\"][-1].tool_calls else END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"agent\", agent)\n",
    "graph_builder.add_node(\"call_tools\", call_tools)\n",
    "\n",
    "graph_builder.set_entry_point(\"agent\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\"agent\", should_continue)\n",
    "\n",
    "graph_builder.add_edge(\"call_tools\", \"agent\")\n",
    "\n",
    "human_feedback_graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(human_feedback_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"Count the lines of all python notebooks in the current directory. Use simple shell commands.\"\n",
    "        )\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in human_feedback_graph.stream(inputs, stream_mode=\"values\"):\n",
    "    message: BaseMessage = event[\"messages\"][-1]\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Das hat funktioniert\n",
    "\n",
    "Allerdings muss nun unsere App den GraphState und alle Objekte so lange im Memory behalten, bis ein Nutzer endlich die R√ºckfrage beantwortet. Asynchron ist das ganz sch√∂n bl√∂d.\n",
    "\n",
    "## L√∂sung 2. LangGraph- Checkpoints\n",
    "\n",
    "Checkpoints sind ein essentieller Baustein von Langgraph. Bis jetzt haben wir noch nichts davon mitbekommen. Was tun Checkpoints und wozu brauchen wir die?\n",
    "\n",
    "Weil das Konzept f√ºr eine reale App mit realen Nutzern sehr schnell relevant wird, erl√§utern wir es hier grob.\n",
    "\n",
    "Wenn eine LangGraph-App mit einem Knoten fertig ist und nachschaut, wohin sie jetzt weiterh√ºpft (zu welchem Knoten), speichert sie erst einmal den State (und noch andere Dinge) in einen Checkpoint. Das passiert alles in einem kleinen Memory-Objekt und muss uns nicht weiter interessieren. Der n√§chste Knoten liest dann aus dem Checkpoint des letzten Knoten aus und setzt daran an. Dieses Memory-Objekt ist allerdings volatil und wird gel√∂scht, nachdem der Graph fertig durchgelaufen ist.\n",
    "\n",
    "Man kann aber auch den State √ºber Graph invokations hinweg persistieren. Z.B. in SQL, Redis, etc...\n",
    "\n",
    "Was bringt das?\n",
    "\n",
    "Nun kann ein Nutzer eine App, die ihm zu lange braucht, terminieren. Bisher abgelaufene Zwischenst√§nde gehen nicht verloren. Er kann die App dann entweder neu starten oder auf dem letzten Zwischenstand aufsetzen.\n",
    "Man kann der App befehlen, vor einem bestimmten Knoten immer zu terminieren. Der Zwischenstand speichert sich automatisch und der Nutzer muss dann die App erneut dort aufrufen (Das bauen wir jetzt).\n",
    "Man kann verteilte Systeme bauen, in denen Komponenten ihren Arbeitstand untereinander mittels der Datenbank austauschen.\n",
    "Man kann die Checkpoints auch f√ºr die Chathistory verwenden. Damit hat man dann einen Chatbot mit Ged√§chtnis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsafe_call_tools(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    return {\"messages\": tool_executor.batch(last_message.tool_calls)}\n",
    "\n",
    "\n",
    "def should_continue(state) -> Literal[\"action\", END]:  # type: ignore\n",
    "    return \"action\" if state[\"messages\"][-1].tool_calls else END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Jetzt kompilieren wir erneut\n",
    "\n",
    "Diesmal mit\n",
    "\n",
    "unsafe_execute_tools\n",
    "Checkpointer\n",
    "Interrupt vor der \"action\"-Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir nehmen hier einfach den In-Memory Checkpointer und keine umst√§ndliche Datenbank\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"agent\", agent)\n",
    "graph_builder.add_node(\"action\", unsafe_call_tools)\n",
    "graph_builder.set_entry_point(\"agent\")\n",
    "graph_builder.add_conditional_edges(\"agent\", should_continue)\n",
    "graph_builder.add_edge(\"action\", \"agent\")\n",
    "\n",
    "checkpoint_agent_executor = graph_builder.compile(\n",
    "    checkpointer=memory, interrupt_before=[\"action\"]\n",
    ")\n",
    "checkpoint_agent_executor.stream_mode = \"values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "for event in checkpoint_agent_executor.stream(inputs, config):\n",
    "    message: BaseMessage = event[\"messages\"][-1]\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Oh, jetzt hat er tats√§chlich abgebrochen. Mal sehen, was der State ist:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = checkpoint_agent_executor.get_state(config)\n",
    "for message in current_state.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Wir k√∂nnen auch sehen, was die n√§chste Node im Flow w√§re.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Weiter ausf√ºhren geht mit None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in checkpoint_agent_executor.stream(None, config):\n",
    "    message: BaseMessage = event[\"messages\"][-1]\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = checkpoint_agent_executor.get_state(config)\n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## ‚úÖ Aufgabe\n",
    "\n",
    "### State modifizieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"17\"}}\n",
    "for event in checkpoint_agent_executor.stream(inputs, config):\n",
    "    message: BaseMessage = event[\"messages\"][-1]\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = checkpoint_agent_executor.get_state(config)\n",
    "current_state.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Wir √ºberschreiben jetzt einfach das Terminal Tool Call Argument im State...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tool_call = \"echo 'YOUR CREATIVE ECHO MESSAGE GOES HERE'\"\n",
    "\n",
    "current_state.values[\"messages\"][-1].tool_calls[0][\"args\"][\"commands\"] = [new_tool_call]\n",
    "\n",
    "checkpoint_agent_executor.update_state(config, current_state.values)\n",
    "\n",
    "checkpoint_agent_executor.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in checkpoint_agent_executor.stream(None, config):\n",
    "    message: BaseMessage = event[\"messages\"][-1]\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
